{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "029df26da5ee4f26a6c60259c1502600": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b9b7818dca7240238496ffb19239cef1",
              "IPY_MODEL_a9c204e95e0f4c1199a30b869ce83717",
              "IPY_MODEL_a21262dc074a4e28a96c1f8ed7636575"
            ],
            "layout": "IPY_MODEL_09954be52c3d46168fc633f7814f0f97"
          }
        },
        "b9b7818dca7240238496ffb19239cef1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f96ad3258a79417298302a91324e00c6",
            "placeholder": "​",
            "style": "IPY_MODEL_a1087e16c8624d3d8bce2fc234afd17f",
            "value": "100%"
          }
        },
        "a9c204e95e0f4c1199a30b869ce83717": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ad03e332ee34b0c8f7990a34a978ff6",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5dff48221656446ab514777be1af11e7",
            "value": 50
          }
        },
        "a21262dc074a4e28a96c1f8ed7636575": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1fe4c8fdc5b3426f856c34703f848140",
            "placeholder": "​",
            "style": "IPY_MODEL_e81cbd82141a4e0895c98c6f22c84625",
            "value": " 50/50 [00:40&lt;00:00,  1.11it/s]"
          }
        },
        "09954be52c3d46168fc633f7814f0f97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f96ad3258a79417298302a91324e00c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1087e16c8624d3d8bce2fc234afd17f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ad03e332ee34b0c8f7990a34a978ff6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5dff48221656446ab514777be1af11e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1fe4c8fdc5b3426f856c34703f848140": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e81cbd82141a4e0895c98c6f22c84625": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Midi generation using the PyTorch"
      ],
      "metadata": {
        "id": "snr9V0hjj7DJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "uvvnZOmPZ2sb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import random\n",
        "import pickle\n",
        "import json\n",
        "import numpy as np\n",
        "import music21 as m21\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from tqdm.auto import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### For reproducibility"
      ],
      "metadata": {
        "id": "UNtl5mWHgTLy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RANDOM_SEED = 42\n",
        "\n",
        "random.seed(RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "torch.cuda.manual_seed(RANDOM_SEED)\n",
        "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
        "\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "sn0Utwi9fWXL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configutation"
      ],
      "metadata": {
        "id": "wTWIV9WWge4n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LEN = 32\n",
        "BATCH_SIZE = 64\n",
        "EMBEDDING_DIM = 256\n",
        "HIDDEN_DIM = 256\n",
        "LEARNING_RATE = 0.001\n",
        "EPOCHS = 10 # Reduced for testing, can be increased\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "print(f\"Notebook is using device: {DEVICE}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1pybNr8gd8Q",
        "outputId": "fc6ac6f1-f641-4bd7-d9e2-65e14696037d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Notebook is using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-M-bu6Mh67S",
        "outputId": "5f750ec4-2ff0-46ba-fa7d-0962ad773be9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# there are about 5000 midi files but just use 50 music for now\n",
        "DATA_PATH = \"/content/drive/MyDrive/essen-dataset/*\"\n",
        "midi_file_paths = glob.glob(DATA_PATH)[:50]\n",
        "print(f'Total files in dataset: {len(midi_file_paths)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4UYC9dFh8tg",
        "outputId": "1ed75736-46eb-48b6-868b-a9f96cb2aa8c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total files in dataset: 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Processing"
      ],
      "metadata": {
        "id": "Zs0Op2fwgssR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_musical_data(song):\n",
        "    pitches = []\n",
        "    durations = []\n",
        "    for element in song.flat.notesAndRests:\n",
        "        if isinstance(element, m21.chord.Chord):\n",
        "            if element.duration.quarterLength > 4:\n",
        "                continue\n",
        "            sorted_pitches = sorted([n.nameWithOctave for n in element.pitches])\n",
        "            pitches.append('.'.join(sorted_pitches))\n",
        "            durations.append(element.duration.quarterLength)\n",
        "        elif isinstance(element, m21.note.Rest):\n",
        "            if element.duration.quarterLength > 4:\n",
        "                continue\n",
        "            pitches.append('rest')\n",
        "            durations.append(element.duration.quarterLength)\n",
        "        elif isinstance(element, m21.note.Note):\n",
        "            if element.duration.quarterLength > 4:\n",
        "                continue\n",
        "            pitches.append(str(element.nameWithOctave))\n",
        "            durations.append(element.duration.quarterLength)\n",
        "    return pitches, durations\n",
        "\n",
        "def normalize_key(song):\n",
        "    interval = m21.interval.Interval(0)\n",
        "    try:\n",
        "        key = song.analyze(\"key\")\n",
        "        if key.mode == \"major\":\n",
        "            interval = m21.interval.Interval(key.tonic, m21.pitch.Pitch(\"C\"))\n",
        "        elif key.mode == \"minor\":\n",
        "            interval = m21.interval.Interval(key.tonic, m21.pitch.Pitch(\"A\"))\n",
        "    except:\n",
        "        pass\n",
        "    return song.transpose(interval)"
      ],
      "metadata": {
        "id": "1SMeU8RWgu8O"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_pitches = []\n",
        "dataset_durations = []\n",
        "\n",
        "for file_path in tqdm(midi_file_paths):\n",
        "    try:\n",
        "        song = m21.converter.parse(file_path).chordify()\n",
        "        song = normalize_key(song)\n",
        "        pitches, durations = get_musical_data(song)\n",
        "        if pitches:\n",
        "            dataset_pitches.append(pitches)\n",
        "            dataset_durations.append(durations)\n",
        "    except Exception as e:\n",
        "        print(f\"Error parsing {file_path}: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106,
          "referenced_widgets": [
            "029df26da5ee4f26a6c60259c1502600",
            "b9b7818dca7240238496ffb19239cef1",
            "a9c204e95e0f4c1199a30b869ce83717",
            "a21262dc074a4e28a96c1f8ed7636575",
            "09954be52c3d46168fc633f7814f0f97",
            "f96ad3258a79417298302a91324e00c6",
            "a1087e16c8624d3d8bce2fc234afd17f",
            "5ad03e332ee34b0c8f7990a34a978ff6",
            "5dff48221656446ab514777be1af11e7",
            "1fe4c8fdc5b3426f856c34703f848140",
            "e81cbd82141a4e0895c98c6f22c84625"
          ]
        },
        "id": "3Xcb84JsiUaN",
        "outputId": "9e153faf-548d-4ab1-c3df-c0ff4e014d50"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "029df26da5ee4f26a6c60259c1502600"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/music21/stream/base.py:3675: Music21DeprecationWarning: .flat is deprecated.  Call .flatten() instead\n",
            "  return self.iter().getElementsByClass(classFilterList)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_unique_tokens(elements):\n",
        "    token_names = sorted(set(elements))\n",
        "    return token_names, len(token_names)\n",
        "\n",
        "def create_vocabulary_mappings(token_names):\n",
        "    token_to_int = {str(token): number for number, token in enumerate(token_names)}\n",
        "    int_to_token = {number: str(token) for number, token in enumerate(token_names)}\n",
        "    return token_to_int, int_to_token"
      ],
      "metadata": {
        "id": "FbaunvYHidoz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build Vocabulary\n",
        "flat_pitches = [p for song in dataset_pitches for p in song]\n",
        "flat_durations = [d for song in dataset_durations for d in song]\n",
        "\n",
        "unique_pitches, n_unique_pitches = get_unique_tokens(flat_pitches)\n",
        "unique_durations, n_unique_durations = get_unique_tokens(flat_durations)\n",
        "\n",
        "print(f\"Unique Pitches: {n_unique_pitches}, Unique Durations: {n_unique_durations}\")\n",
        "\n",
        "pitch_to_int, int_to_pitch = create_vocabulary_mappings(unique_pitches)\n",
        "duration_to_int, int_to_duration = create_vocabulary_mappings(unique_durations)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8EtGFAcid49",
        "outputId": "0bff8958-ad62-478d-93bf-4885d484e179"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique Pitches: 33, Unique Durations: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save vocab mappings\n",
        "with open('pt_int_to_pitch.json', 'w') as f: json.dump(int_to_pitch, f)\n",
        "with open('pt_int_to_duration.json', 'w') as f: json.dump(int_to_duration, f)"
      ],
      "metadata": {
        "id": "ZGryxjiKil3K"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def generate_midi_stream(composition_data):\n",
        "    midi_stream = m21.stream.Stream()\n",
        "    midi_stream.append(m21.instrument.Piano())\n",
        "\n",
        "    for element in composition_data:\n",
        "        pitch_pattern, duration_val = element\n",
        "\n",
        "        if '.' in pitch_pattern:\n",
        "            notes_in_chord = pitch_pattern.split('.')\n",
        "            chord_notes = []\n",
        "            for note_name in notes_in_chord:\n",
        "                new_note = m21.note.Note(note_name)\n",
        "                new_note.duration = m21.duration.Duration(quarterLength=duration_val)\n",
        "                chord_notes.append(new_note)\n",
        "            new_chord = m21.chord.Chord(chord_notes)\n",
        "            midi_stream.append(new_chord)\n",
        "        elif pitch_pattern == 'rest':\n",
        "            new_rest = m21.note.Rest()\n",
        "            new_rest.duration = m21.duration.Duration(quarterLength=duration_val)\n",
        "            midi_stream.append(new_rest)\n",
        "        else:\n",
        "            new_note = m21.note.Note(pitch_pattern)\n",
        "            new_note.duration = m21.duration.Duration(quarterLength=duration_val)\n",
        "            midi_stream.append(new_note)\n",
        "\n",
        "    return midi_stream\n",
        "\n",
        "def round_duration(duration):\n",
        "    standard_durations = [0.25, 0.5, 0.75, 1.0, 1.5, 2.0, 3.0, 4.0]\n",
        "    return min(standard_durations, key=lambda x: abs(x - duration))\n",
        "\n",
        "def fraction(duration_str):\n",
        "    if '/' in duration_str:\n",
        "        lst = duration_str.split('/')\n",
        "        return int(lst[0])/int(lst[1])\n",
        "    else:\n",
        "        try:\n",
        "            return float(duration_str)\n",
        "        except:\n",
        "            return 0.25\n",
        "\n",
        "def sample_with_temp(logits, temperature):\n",
        "    if temperature == 0:\n",
        "        return torch.argmax(logits).item()\n",
        "    logits = logits / temperature\n",
        "    probs = torch.softmax(logits, dim=-1)\n",
        "    return torch.multinomial(probs, 1).item()"
      ],
      "metadata": {
        "id": "FESM8jD6gyY4"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset"
      ],
      "metadata": {
        "id": "hlyraViWhF9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MidiDataset(Dataset):\n",
        "    def __init__(self, pitches, durations, pitch_to_int, duration_to_int, seq_len=32):\n",
        "        self.pitch_to_int = pitch_to_int\n",
        "        self.duration_to_int = duration_to_int\n",
        "        self.seq_len = seq_len\n",
        "        self.pitch_seqs = []\n",
        "        self.duration_seqs = []\n",
        "        self.pitch_targets = []\n",
        "        self.duration_targets = []\n",
        "\n",
        "        for p_list, d_list in zip(pitches, durations):\n",
        "            for i in range(len(p_list) - seq_len):\n",
        "                p_in = [self.pitch_to_int[p] for p in p_list[i:i + seq_len]]\n",
        "                p_out = self.pitch_to_int[p_list[i + seq_len]]\n",
        "\n",
        "                d_in = [self.duration_to_int[str(d)] for d in d_list[i:i + seq_len]]\n",
        "                d_out = self.duration_to_int[str(d_list[i + seq_len])]\n",
        "\n",
        "                self.pitch_seqs.append(p_in)\n",
        "                self.duration_seqs.append(d_in)\n",
        "                self.pitch_targets.append(p_out)\n",
        "                self.duration_targets.append(d_out)\n",
        "\n",
        "        self.pitch_seqs = torch.tensor(self.pitch_seqs, dtype=torch.long)\n",
        "        self.duration_seqs = torch.tensor(self.duration_seqs, dtype=torch.long)\n",
        "        self.pitch_targets = torch.tensor(self.pitch_targets, dtype=torch.long)\n",
        "        self.duration_targets = torch.tensor(self.duration_targets, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pitch_seqs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return (self.pitch_seqs[idx], self.duration_seqs[idx]), (self.pitch_targets[idx], self.duration_targets[idx])"
      ],
      "metadata": {
        "id": "PqC2SOYmg7Mh"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare Dataset\n",
        "dataset = MidiDataset(dataset_pitches, dataset_durations,\n",
        "                      pitch_to_int, duration_to_int, seq_len=SEQ_LEN)\n",
        "\n",
        "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "metadata": {
        "id": "AVj5S29vism2"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model"
      ],
      "metadata": {
        "id": "NYzgT-yUhQaj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MidiGenerationModel(nn.Module):\n",
        "    def __init__(self, n_pitches, n_durations, pitch_embed_dim=128, duration_embed_dim=32):\n",
        "        super(MidiGenerationModel, self).__init__()\n",
        "\n",
        "        self.pitch_embedding = nn.Embedding(n_pitches, pitch_embed_dim)\n",
        "        self.duration_embedding = nn.Embedding(n_durations, duration_embed_dim)\n",
        "        # Using Dropout1d for SpatialDropout1D behavior\n",
        "        self.dropout_emb = nn.Dropout1d(0.2)\n",
        "\n",
        "        input_dim = pitch_embed_dim + duration_embed_dim\n",
        "        self.ln_emb = nn.LayerNorm(input_dim)\n",
        "\n",
        "        self.lstm1 = nn.LSTM(input_dim, 256, batch_first=True)\n",
        "        self.dropout1 = nn.Dropout(0.2)\n",
        "\n",
        "        self.lstm2 = nn.LSTM(256, 128, batch_first=True)\n",
        "        self.dropout2 = nn.Dropout(0.2)\n",
        "\n",
        "        self.lstm3 = nn.LSTM(128, 128, batch_first=True)\n",
        "        self.ln_lstm3 = nn.LayerNorm(128)\n",
        "\n",
        "        self.dense = nn.Linear(128, 128)\n",
        "        self.dropout_dense = nn.Dropout(0.2)\n",
        "\n",
        "        self.pitch_head = nn.Linear(128, n_pitches)\n",
        "        self.duration_head = nn.Linear(128, n_durations)\n",
        "\n",
        "    def forward(self, pitch_seq, duration_seq):\n",
        "        p_emb = self.pitch_embedding(pitch_seq)\n",
        "        d_emb = self.duration_embedding(duration_seq)\n",
        "\n",
        "        x = torch.cat([p_emb, d_emb], dim=2)\n",
        "\n",
        "        # SpatialDropout1D equivalent: Drop entire channels across the sequence\n",
        "        # Input to Dropout1d should be (batch, channel, seq_len)\n",
        "        x = x.transpose(1, 2)\n",
        "        x = self.dropout_emb(x)\n",
        "        x = x.transpose(1, 2)\n",
        "\n",
        "        x = self.ln_emb(x)\n",
        "\n",
        "        x, _ = self.lstm1(x)\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x, _ = self.lstm2(x)\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        _, (h_n, _) = self.lstm3(x)\n",
        "        c = h_n[-1]\n",
        "        c = self.ln_lstm3(c)\n",
        "\n",
        "        c = torch.relu(self.dense(c))\n",
        "        c = self.dropout_dense(c)\n",
        "\n",
        "        pitch_out = self.pitch_head(c)\n",
        "        duration_out = self.duration_head(c)\n",
        "\n",
        "        return pitch_out, duration_out"
      ],
      "metadata": {
        "id": "kbxD6rHhhRiA"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Model\n",
        "model = MidiGenerationModel(n_unique_pitches, n_unique_durations).to(DEVICE)\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "UJmiEzfui2UF"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Loop\n",
        "print(\"Starting Training...\")\n",
        "model.train()\n",
        "for epoch in range(EPOCHS):\n",
        "    total_loss = 0\n",
        "    for (pitch_in, duration_in), (pitch_target, duration_target) in dataloader:\n",
        "        pitch_in, duration_in = pitch_in.to(DEVICE), duration_in.to(DEVICE)\n",
        "        pitch_target, duration_target = pitch_target.to(DEVICE), duration_target.to(DEVICE)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        pitch_out, duration_out = model(pitch_in, duration_in)\n",
        "\n",
        "        loss_pitch = criterion(pitch_out, pitch_target)\n",
        "        loss_duration = criterion(duration_out, duration_target)\n",
        "        loss = loss_pitch + loss_duration\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {total_loss/len(dataloader):.4f}\")\n",
        "\n",
        "# Save Model\n",
        "torch.save(model.state_dict(), 'midi_model.pth')\n",
        "print(\"Model saved to midi_model.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRmirz4NjA7J",
        "outputId": "38b83ad7-b4b7-4a39-aa37-34b7cfee8536"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Training...\n",
            "Epoch 1/10, Loss: 0.3905\n",
            "Epoch 2/10, Loss: 0.3414\n",
            "Epoch 3/10, Loss: 0.3584\n",
            "Epoch 4/10, Loss: 0.3275\n",
            "Epoch 5/10, Loss: 0.3315\n",
            "Epoch 6/10, Loss: 0.3274\n",
            "Epoch 7/10, Loss: 0.3746\n",
            "Epoch 8/10, Loss: 0.3503\n",
            "Epoch 9/10, Loss: 0.3778\n",
            "Epoch 10/10, Loss: 0.2474\n",
            "Model saved to midi_model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference"
      ],
      "metadata": {
        "id": "UNuuEVuqjC2x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generation\n",
        "print(\"Generating Music...\")\n",
        "model.eval()\n",
        "\n",
        "# Pick random seed from dataset\n",
        "if len(dataset_pitches) > 0 and len(dataset_pitches[0]) > SEQ_LEN:\n",
        "    song_idx = np.random.randint(len(dataset_pitches))\n",
        "    start_idx = np.random.randint(len(dataset_pitches[song_idx]) - SEQ_LEN)\n",
        "\n",
        "    seed_pitch = [pitch_to_int[p] for p in dataset_pitches[song_idx][start_idx:start_idx+SEQ_LEN]]\n",
        "    seed_duration = [duration_to_int[str(d)] for d in dataset_durations[song_idx][start_idx:start_idx+SEQ_LEN]]\n",
        "else:\n",
        "    # Fallback random seed\n",
        "    seed_pitch = [np.random.randint(n_unique_pitches) for _ in range(SEQ_LEN)]\n",
        "    seed_duration = [np.random.randint(n_unique_durations) for _ in range(SEQ_LEN)]\n",
        "\n",
        "curr_pitch_seq = seed_pitch\n",
        "curr_duration_seq = seed_duration\n",
        "\n",
        "generated_composition = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for _ in range(100): # Generate 100 notes\n",
        "        p_in = torch.tensor([curr_pitch_seq], dtype=torch.long).to(DEVICE)\n",
        "        d_in = torch.tensor([curr_duration_seq], dtype=torch.long).to(DEVICE)\n",
        "\n",
        "        p_logits, d_logits = model(p_in, d_in)\n",
        "\n",
        "        p_next = sample_with_temp(p_logits[0], 0.5)\n",
        "        d_next_idx = sample_with_temp(d_logits[0], 0.5)\n",
        "\n",
        "        # Decode\n",
        "        p_str = int_to_pitch[p_next]\n",
        "        d_str = int_to_duration[d_next_idx]\n",
        "        d_val = round_duration(fraction(d_str))\n",
        "\n",
        "        generated_composition.append([p_str, d_val])\n",
        "\n",
        "        # Update sequences\n",
        "        curr_pitch_seq = curr_pitch_seq[1:] + [p_next]\n",
        "        curr_duration_seq = curr_duration_seq[1:] + [d_next_idx]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VoVJDOTLhmA6",
        "outputId": "a73953f8-b5a1-491b-b368-cbf2c333b172"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating Music...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save to MIDI\n",
        "midi_stream = generate_midi_stream(generated_composition)\n",
        "output_file = 'generated_pytorch.mid'\n",
        "midi_stream.write('midi', fp=output_file)\n",
        "print(f\"Generated MIDI saved to {output_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsVHiOHIjKPI",
        "outputId": "61754db6-37ca-4bba-d54c-9a7dcaea9248"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated MIDI saved to generated_pytorch.mid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download the generated music file"
      ],
      "metadata": {
        "id": "6F30M-Upjktx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(output_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "JuAk27bgjjsr",
        "outputId": "a8eab6c5-28f3-4d3f-c088-fd7ecc650cf1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f040c64e-efe1-4552-8d84-d913cdb0cb99\", \"generated_pytorch.mid\", 864)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}